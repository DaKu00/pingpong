{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e152aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "\n",
    "BLACK = (0,0,0)\n",
    "\n",
    "class Paddle(pygame.sprite.Sprite):\n",
    "    def __init__(self, color, width, height):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image = pygame.Surface([width, height])\n",
    "        self.image.fill(BLACK)\n",
    "        self.image.set_colorkey(BLACK)\n",
    "\n",
    "        pygame.draw.rect(self.image, color, [0, 0, width, height])\n",
    "\n",
    "        self.rect = self.image.get_rect()\n",
    "\n",
    "    def moveUp(self, pixels):\n",
    "        self.rect.y -= pixels\n",
    "\n",
    "        if self.rect.y < 0:\n",
    "            self.rect.y = 0\n",
    "\n",
    "    def moveDown(self, pixels):\n",
    "        self.rect.y += pixels\n",
    "\n",
    "        if self.rect.y > 400:\n",
    "            self.rect.y = 400\n",
    "            \n",
    "    def get_paddle(self):\n",
    "        return self.rect.y\n",
    "\n",
    "import pygame\n",
    "from random import randint\n",
    "\n",
    "BLACK = (0, 0, 0)\n",
    "\n",
    "class Ball(pygame.sprite.Sprite):\n",
    "\n",
    "    def __init__(self, color, width, height):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image = pygame.Surface([width, height])\n",
    "        self.image.fill(BLACK)\n",
    "        self.image.set_colorkey(BLACK)\n",
    "\n",
    "        pygame.draw.rect(self.image, color, [0, 0, width, height])\n",
    "\n",
    "        self.velocity = [4, randint(-6,6)]\n",
    "\n",
    "        self.rect = self.image.get_rect()\n",
    "\n",
    "        self.tx = 0\n",
    "        self.ty = 0\n",
    "        \n",
    "    def ang(self):\n",
    "        return self.ty / self.tx\n",
    "    \n",
    "    def update(self):\n",
    "        t_x = self.rect.x\n",
    "        t_y = self.rect.y\n",
    "        self.rect.x += self.velocity[0]\n",
    "        self.rect.y += self.velocity[1]\n",
    "        self.tx = t_x - self.rect.x\n",
    "        self.ty = t_y - self.rect.y\n",
    "\n",
    "    def bounceA(self):\n",
    "        self.velocity[0] = -self.velocity[0]\n",
    "        self.velocity[1] = randint(-6,6)\n",
    "        self.rect.x = 11\n",
    "        \n",
    "    def bounceB(self):\n",
    "        self.velocity[0] = -self.velocity[0]\n",
    "        self.velocity[1] = randint(-6,6)\n",
    "        self.rect.x = 680\n",
    "        \n",
    "    def get_ball(self):\n",
    "        return self.rect.x, self.rect.y\n",
    "\n",
    "        \n",
    "from gym.spaces import Discrete, Box\n",
    "import random\n",
    "\n",
    "class pygametest(pygame.sprite.Sprite):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pygame.init()\n",
    "        \n",
    "        #-----------------------------------------------\n",
    "        \n",
    "        self.action_space = Discrete(2)  # 0,1, 두가지 액션, 위아래\n",
    "        \n",
    "        # 상태값을 나타내고, 현 코드에서는 0부터 100까지를 나타낼 것\n",
    "        self.observation_space = Box(low=0, high=5000, shape=(4,), dtype=int) \n",
    "#         self.target = Target()\n",
    "        self.state = (0, 0, 0, 0)\n",
    "        self.episodes = 5000\n",
    "        self.hit = 0\n",
    "        self.count = 0\n",
    "        self.memory = []\n",
    "        self.fire_count = 0\n",
    "        self.rad = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        #-----------------------------------------------\n",
    "        # Define some colors\n",
    "        self.BLACK = (0,0,0)\n",
    "        self.WHITE = (255,255,255)\n",
    "\n",
    "        # Open a new window\n",
    "        self.size = (700, 500)\n",
    "        self.screen = pygame.display.set_mode(self.size)\n",
    "        pygame.display.set_caption(\"Pong\")\n",
    "\n",
    "        self.paddleA = Paddle(self.WHITE, 10, 100)\n",
    "        self.paddleA.rect.x = 0\n",
    "        self.paddleA.rect.y = 200\n",
    "\n",
    "        self.paddleB = Paddle(self.WHITE, 10, 100)\n",
    "        self.paddleB.rect.x = 690\n",
    "        self.paddleB.rect.y = 200\n",
    "\n",
    "        self.balls = []\n",
    "        \n",
    "\n",
    "        self.ball = Ball(self.WHITE,10,10)\n",
    "        self.ball.rect.x = 345\n",
    "        self.ball.rect.y = 195\n",
    "\n",
    "        #This will be a list that will contain all the sprites we intend to use in our game.\n",
    "        self.all_sprites_list = pygame.sprite.Group()\n",
    "\n",
    "        # Add the car to the list of objects\n",
    "        self.all_sprites_list.add(self.paddleA)\n",
    "        self.all_sprites_list.add(self.paddleB)\n",
    "        self.all_sprites_list.add(self.ball)\n",
    "\n",
    "        # The clock will be used to control how fast the screen updates\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "        #Initialise player scores\n",
    "        self.scoreA = 0\n",
    "        self.scoreB = 0\n",
    "        \n",
    "        self.bounce_state = (0, 0, 0, 0)\n",
    "        self.reward_point = 0\n",
    "\n",
    "    def bouncePaddle(self, a, b, x, y):\n",
    "        self.bounce_state = a, b, x, y\n",
    "        \n",
    "    def step(self, act):\n",
    "        self.episodes -= 1\n",
    "        self.count = 0\n",
    "        done = False\n",
    "        \n",
    "#         while not done:\n",
    "            \n",
    "\n",
    "        self.screen.fill(BLACK)\n",
    "        #Draw the net\n",
    "        pygame.draw.line(self.screen, self.WHITE, [349, 0], [349, 500], 5)\n",
    "\n",
    "        # --- Main event loop\n",
    "        self.event = pygame.event.poll()\n",
    "        if self.event.type == pygame.QUIT: # If user clicked close\n",
    "              pygame.quit()\n",
    "        elif self.event.type==pygame.KEYDOWN:\n",
    "                if self.event.key==pygame.K_x: #Pressing the x Key will quit the game\n",
    "                     pygame.quit()\n",
    "\n",
    "        keys = pygame.key.get_pressed()\n",
    "        if act == 0: # keys[pygame.K_w]: # \n",
    "            self.paddleA.moveUp(5)\n",
    "        if act == 1: # keys[pygame.K_s]: #\n",
    "            self.paddleA.moveDown(5)\n",
    "\n",
    "\n",
    "#         rand = random.randrange(2)\n",
    "        if keys[pygame.K_UP]:#rand == 0: # \n",
    "            self.paddleB.moveUp(5)\n",
    "        if keys[pygame.K_DOWN]:# rand == 1: # \n",
    "            self.paddleB.moveDown(5)    \n",
    "\n",
    "        self.all_sprites_list.update()\n",
    "\n",
    "        # a 학습\n",
    "        if self.ball.rect.x>=690:\n",
    "            self.scoreA+=1\n",
    "#             self.count = 1\n",
    "            if self.reward_point == 1:\n",
    "#                 self.count = 10\n",
    "                info = {}\n",
    "                self.reward_point = 0\n",
    "                \n",
    "            \n",
    "            self.ball.velocity[0] = -self.ball.velocity[0]\n",
    "            print(\"득점 : \", self.paddleA.get_paddle(), self.ball.get_ball())\n",
    "        if self.ball.rect.x<=0:\n",
    "            self.scoreB+=1\n",
    "#             done = True\n",
    "            self.count = -50\n",
    "            info = {}\n",
    "            p1 = self.paddleA.get_paddle()\n",
    "            p2 = self.paddleB.get_paddle()\n",
    "            b_x, b_y = self.ball.get_ball()\n",
    "            self.reward_point = 0\n",
    "            self.bouncePaddle(p1, p2, b_x, b_y)\n",
    "            self.ball.velocity[0] = -self.ball.velocity[0]\n",
    "            print(\"짐 : \", self.paddleA.get_paddle(), self.ball.get_ball())\n",
    "            done = True\n",
    "        if self.ball.rect.y>490:\n",
    "            self.ball.velocity[1] = -self.ball.velocity[1]\n",
    "            self.ball.rect.y = 490\n",
    "        if self.ball.rect.y<0:\n",
    "            self.ball.velocity[1] = -self.ball.velocity[1]  \n",
    "            self.ball.rect.y = 0\n",
    "\n",
    "\n",
    "        if pygame.sprite.collide_mask(self.ball, self.paddleA):\n",
    "            print(\"반사 : \", self.paddleA.get_paddle(), self.ball.get_ball())\n",
    "            self.count = 20\n",
    "            info = {}\n",
    "            p1 = self.paddleA.get_paddle()\n",
    "            p2 = self.paddleB.get_paddle()\n",
    "            b_x, b_y = self.ball.get_ball()\n",
    "            self.reward_point = 1\n",
    "            self.bouncePaddle(p1, p2, b_x, b_y)\n",
    "            self.ball.bounceA()\n",
    "#             return (p1, p2, b_x, b_y), self.count, done, info\n",
    "\n",
    "        if pygame.sprite.collide_mask(self.ball, self.paddleB):\n",
    "            print(\"막음 : \", self.paddleA.get_paddle(), self.ball.get_ball())\n",
    "            self.ball.bounceB()\n",
    "            self.reward_point = 0\n",
    "            self.bounce_state = (0, 0, 0, 0)\n",
    "\n",
    "        self.all_sprites_list.draw(self.screen) \n",
    "\n",
    "        font = pygame.font.Font(None, 74)\n",
    "        text = font.render('AI :'+ str(self.scoreA), 1, self.WHITE)\n",
    "        self.screen.blit(text, (150,10))\n",
    "        text = font.render('User :' + str(self.scoreB), 1, self.WHITE)\n",
    "        self.screen.blit(text, (420,10))\n",
    "\n",
    "        pygame.display.update()\n",
    "\n",
    "        self.clock.tick(60)\n",
    "\n",
    "\n",
    "        if self.episodes <= 0:\n",
    "            done = True\n",
    "\n",
    "        info = {}\n",
    "        p1 = self.paddleA.get_paddle()\n",
    "        p2 = self.paddleB.get_paddle()\n",
    "        b_x, b_y = self.ball.get_ball()\n",
    "        return (p1, self.ball.velocity[0], b_x, b_y), self.count, done, info\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = (0,0)\n",
    "        self.episodes = 5000\n",
    "        self.count = 0\n",
    "        \n",
    "        self.paddleA.rect.x = 0\n",
    "        self.paddleA.rect.y = 200\n",
    "\n",
    "        self.paddleB.rect.x = 690\n",
    "        self.paddleB.rect.y = 200\n",
    "        \n",
    "        self.bounce_state = (0, 0, 0, 0)\n",
    "\n",
    "        self.ball.rect.x = 345\n",
    "        self.ball.rect.y = 195\n",
    "        self.ball.velocity = [4, randint(-6,6)]\n",
    "        return 0,0,0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5cd9af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea09ab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, action_space):\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = Dense(16, input_shape=input_shape, activation=\"relu\", kernel_initializer='he_uniform')(X_input)\n",
    "    X = Dense(16, activation=\"relu\", kernel_initializer='he_uniform')(X)\n",
    "    X = Dense(32, activation=\"linear\", kernel_initializer='he_uniform')(X)\n",
    "    X = Dense(16, activation=\"relu\", kernel_initializer='he_uniform')(X)\n",
    "    X = Dense(action_space, activation=\"linear\", kernel_initializer='he_uniform')(X)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X, name='CartPoleDQNmodel')\n",
    "    model.compile(loss=\"mse\", optimizer=RMSprop(lr=0.00025, rho=0.95, epsilon=0.01), metrics=[\"accuracy\"])   \n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b8b384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        self.env = pygametest()\n",
    "        self.state_size = self.env.observation_space.shape[0] # 4 차원\n",
    "        print(self.state_size)\n",
    "        self.action_size = self.env.action_space.n#2\n",
    "        self.EPISODES = 500\n",
    "        self.memory = deque(maxlen=3000)\n",
    "            \n",
    "        self.gamma = 0.95   \n",
    "        self.epsilon = 1.0 \n",
    "        self.epsilon_min = 0.001\n",
    "        self.epsilon_decay = 0.9999\n",
    "        self.batch_size = 64\n",
    "        self.train_start = 1000\n",
    "\n",
    "#         self.model = build_model(input_shape=(self.state_size,), action_space = self.action_size)\n",
    "        self.model2 = load_model(\"Not_show_train2.h5\")\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        if len(self.memory) > self.train_start:\n",
    "            if self.epsilon > self.epsilon_min:\n",
    "                self.epsilon *= self.epsilon_decay             \n",
    "        \n",
    "    def act(self, state):\n",
    "        if np.random.random() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            return np.argmax(self.model.predict(state))\n",
    "        \n",
    "\n",
    "    def replay(self):\n",
    "        if len(self.memory) < self.train_start:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, min(len(self.memory), self.batch_size))\n",
    "        \n",
    "\n",
    "        state = np.zeros((self.batch_size, self.state_size))\n",
    "        next_state = np.zeros((self.batch_size, self.state_size))\n",
    "        action, reward, done = [], [], []\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            state[i] = minibatch[i][0]\n",
    "            action.append(minibatch[i][1])\n",
    "            reward.append(minibatch[i][2])\n",
    "            next_state[i] = minibatch[i][3]\n",
    "            done.append(minibatch[i][4])\n",
    "\n",
    "        target = self.model.predict(state)\n",
    "        target_next = self.model.predict(next_state)\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            if done[i]:\n",
    "                target[i][action[i]] = reward[i]\n",
    "            else:\n",
    "                target[i][action[i]] = reward[i] + self.gamma * (np.amax(target_next[i]))\n",
    "\n",
    "        self.model.fit(state, target, batch_size=self.batch_size, verbose=0)\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model = load_model(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save(name)\n",
    "\n",
    "    def run(self):\n",
    "        re_count = 0\n",
    "\n",
    "        for e in range(500):\n",
    "            state = self.env.reset() \n",
    "            state = np.reshape(state, [1, self.state_size])\n",
    "            \n",
    "#             state2 = state\n",
    "#             state2[0][2] = 200 - state[0][2]\n",
    "            \n",
    "            done = False \n",
    "            i = 0\n",
    "            \n",
    "            while not done:\n",
    "                # 학습시킬 A패들\n",
    "#                 action = self.act(state)\n",
    "                \n",
    "                # 학습시킬 B패들\n",
    "#                 action2 = self.act(state)\n",
    "                # 학습중\n",
    "                # 학습된 A패들\n",
    "                action = np.argmax(self.model2.predict(state))\n",
    "                # 학습된 B패들\n",
    "#                 action2 = np.argmax(self.model2.predict(state))\n",
    "            \n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "#                 print(reward)\n",
    "#                 print(type(reward))\n",
    "                next_state = np.reshape(next_state, [1, self.state_size])\n",
    "    \n",
    "#                 time.sleep(0.2)\n",
    "#                 if not done or i == self.env.episodes-1:\n",
    "#                     reward = reward\n",
    "#                 elif done and i != self.env.episodes-1:\n",
    "#                     reward = -100\n",
    "                \n",
    "                # A패들 remember\n",
    "#                 if reward != 0:\n",
    "# #                     print(reward)\n",
    "#                     self.remember(state, action, reward, next_state, done)\n",
    "#                 # B패들 remember\n",
    "# #                 self.remember(state, action2, reward, next_state, done)\n",
    "                \n",
    "                state = next_state\n",
    "\n",
    "#                 self.replay()\n",
    "\n",
    "    def test(self):\n",
    "        self.load(\"show_train.h5\")\n",
    "        for e in range(self.EPISODES):\n",
    "            state = self.env.reset()\n",
    "            state = np.reshape(state, [1, self.state_size])\n",
    "            done = False\n",
    "            i = 0\n",
    "            while not done:\n",
    "#                 self.env.render()\n",
    "                action = np.argmax(self.model2.predict(state))\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                state = np.reshape(next_state, [1, self.state_size])\n",
    "                i += 1\n",
    "                if done:\n",
    "                    print(\"episode: {}/{}, score: {}\".format(e, self.EPISODES, i))\n",
    "                    break\n",
    "                self.replay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec0202aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "막음 :  270 (681, 370)\n",
      "반사 :  220 (8, 276)\n",
      "막음 :  310 (683, 425)\n",
      "반사 :  165 (8, 220)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "video system not initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-fc0a2285b71e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDQNAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-8e3400439cc1>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;31m#                 action2 = np.argmax(self.model2.predict(state))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                 \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;31m#                 print(reward)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;31m#                 print(type(reward))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-5dcd19be88c9>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, act)\u001b[0m\n\u001b[0;32m    184\u001b[0m                      \u001b[0mpygame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpygame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_pressed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mact\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# keys[pygame.K_w]: #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpaddleA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoveUp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: video system not initialized"
     ]
    }
   ],
   "source": [
    "agent = DQNAgent()\n",
    "agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0e1fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
